\addcontentsline{toc}{chapter}{Занятие 7. Гауссовые системы}
\chapter*{Занятие 7. Гауссовые системы}

\addcontentsline{toc}{section}{Контрольные вопросы и задания}
\section*{Контрольные вопросы и задания}

\subsubsection*{Приведите определение гауссового случайного вектора,
                ковариационной матрицы гауссового случаайного вектора.}

$ \vec{ \xi } = \left( \xi_1, \dotsc, \xi_n \right) $ --- гауссовый, если
$$ \forall \alpha_1, \dotsc, \alpha_n: \,
  \sum \limits_{k = 1}^n \alpha_k \xi_k$$
--- гауссовская случайная величина.

$A = cov_{ \vec{ \xi } \vec{ \xi }}, \,
  A_{ij} =
  cov \left( \xi_i, \xi_j \right) =
  M \left( \xi_i \xi_j \right) - M \xi_i M \xi_j$.

\subsubsection*{Какими свойствами владеет ковариационная матрица?}

$A_{ii} = D \xi_i \geq 0$ --- на диагонале --- неотрицательные числа.

Матрица симметрична: $A_{ij} = A_{ji}$.

Матрица неотрицательно определена.

\subsubsection*{Как изменяются характеристики гауссового случайного
                вектора при действии на него линейного оператора?}
Пускай $ \vec{ \xi }$ случайный $n$-элементный вектор,
имеющий гауссовское распределение с параметрами $ \vec{a}$ и
$A, \,
  \vec{ \xi } \sim N \left( \vec{a}, A \right), \,
  \vec{b} \in \mathbb{R}^m, \,
  T \in \mathbb{R}^{m \times n}$.
Тогда $T \vec{ \xi } + \vec{b} \sim N \left( T \vec{a} + \vec{b}, TAT^* \right) $.

\subsubsection*{При каких условиях гауссовский случайный вектор имеет плотность распределения?}

Плотность можно записать только в случае, когда $det \, A \neq 0$.

\subsubsection*{Запишите плотность распределения гауссового случайного вектора.}

$$p_{ \vec{ \xi }} \left( \vec{x} \right) =
  \left( \frac{1}{ \sqrt{2 \pi }} \right)^n \cdot \frac{1}{ \sqrt{det \, A}} \cdot
  e^{- \frac{1}{2} \left[ \vec{x} - \vec{a}, A^{-1} \left( \vec{x} - \vec{a} \right) \right] }.$$

\subsubsection*{Сформулируйте теорему про нормальную корреляцию.}

Есть гауссоский вектор $ \vec{ \xi } \circ \vec{ \eta }$ с ненулевой ковариацией
$cov_{ \vec{ \xi } \circ \vec{ \eta }, \vec{ \xi } \circ \vec{ \eta }} \neq 0$.

Определитель ковариационной матрицы вектора $ \eta $ положителен
$$det \, cov_{ \vec{ \eta }, \vec{ \eta }} \geq
  0.$$

Тогда вектор $ \vec{ \xi }$ при условии $ \vec{ \eta }$ ---
гауссовский случайный вектор
$$ \left. \vec{ \xi} \right| \vec{ \eta } \sim
  N \left( \vec{m}, D \right).$$

Параметры $ \vec{m}$ и $D$ имеют следующий вид
$$ \vec{m} =
  M \vec{ \xi } +
  cov_{ \vec{ \xi }, \vec{ \eta }}
    cov_{ \vec{ \eta }, \vec{ \eta }^{-1}} \left( \eta - M \vec{ \eta } \right), \,
  D =
  cov_{ \vec{ \xi }, \vec{ \xi }} -
  cov_{ \vec{ \xi }, \vec{ \eta }} cov_{ \vec{ \eta }, \vec{ \eta }}^{-1}
    cov_{ \vec{ \eta }, \vec{ \xi }}.$$

\addcontentsline{toc}{section}{Аудиторные задачи}
\section*{Аудиторные задачи}

\subsubsection*{7.3}

\textit{Задание.}
Может ли матрица $A$ быть ковариационной матрицей гауссового случайного вектора, если:
\begin{enumerate}[label=\alph*)]
  \item $A =
    \begin{bmatrix}
      1 & 0 & 0 \\
      0 & 0 & 0
    \end{bmatrix};$
  \item $A =
    \begin{bmatrix}
      1 & 2 \\
      3 & 9
    \end{bmatrix};$
  \item $A =
    \begin{bmatrix}
      4 & 2 \\
      2 & -1
    \end{bmatrix};$
  \item $A =
    \begin{bmatrix}
      1 & 2 \\
      2 & 5
    \end{bmatrix};$
  \item $A =
    \begin{bmatrix}
      1 & 2 & 1 \\
      2 & 6 & -1 \\
      1 & -1 & 12
    \end{bmatrix};$
  \item $A =
    \begin{bmatrix}
      1 & 2 & 1 \\
      2 & 5 & 0 \\
      1 & 0 & 10
    \end{bmatrix}.$
\end{enumerate}
Если так, то предъявите такой вектор.

\textit{Решение.}
\begin{enumerate}[label=\alph*)]
  \item Нет (матрица не квадратная);
  \item нет (матрица не симметрична);
  \item нет (на диагонали отрицательные числа);
  \item матрица квадратная, симметричная, неотрицательно определённая, на диагонали ---
  неотрицательные числа;
  \item матрица квадратная, симметричная, на диагонали --- неотрицательные числа.
  Первый минор $M_1 = 1 \geq 0$, второй минор $M_2 = 6 - 4 = 2 \geq 0$, третий минор
  $$det \left(
      \begin{bmatrix}
        1 & 2 & 1 \\
        2 & 6 & -1 \\
        1 & -1 & 12
      \end{bmatrix}
    \right) =
    1 \cdot \left( 72 - 1 \right) - 2 \cdot \left( 24 + 1 \right) + 1 \cdot \left( -2 - 6 \right) =
    13 \geq
    0,$$
  значит, матрица неотрицательно определена,
  то есть может быть ковариационной матрицей гауссового случайного вектора;
  \item матрица квадратная, симметричная, на диагонали --- неотрицательные чиста.
  Первый минор $M_1 = 1 \geq 0$, второй минор $M_2 = 5 - 2 = 3 \geq 0$,
  третий минор
  $$M_3 =
    1 \cdot \left( 50 - 0 \right) - 2 \cdot \left( 20 - 0 \right) + 1 \cdot \left( 0 - 5 \right) =
    50 - 40 - 5 =
    5 \geq
    0,$$
  значит, матрица неотрицательно определена,
  то есть может быть ковариационной матрицей гауссового случайного вектора.
\end{enumerate}

\subsubsection*{7.5}

\textit{Задание.}
Пусть $ \xi = \left( \xi_1, \xi_2, \xi_3 \right) $ ---
гауссовый вектор с математическим ожиданием $ \left( -1, 0, 2 \right) $
и матрицей ковариаций из задачи 7.3 e).
\begin{enumerate}[label=\alph*)]
  \item Выпишите плотность распределения и характеристическую фукнцию для
  $ \xi_1, \,
    \left( \xi_1, \xi_2 \right), \,
    \xi $.
  \item Найдите матрицу ковариаций и математическое ожидание для вектора
  $ \left( \eta_1, \eta_2, \eta_3 \right) $,
  где $ \eta_1 = \xi_1 - \xi_2, \, \eta_2 = \xi_1 + 2 \xi_2 + 3 \xi_3, \, \eta_3 = \xi_3$.
  \item Вычислите $M \eta_2^2, \, M \eta_2^3, \, M \eta_2^4$.
  \item Выясните, являются ли случайные величины $ \eta_1$ и $ \eta_2$ независимыми.
  \item Найдите
  $M \left( \xi \; \middle| \; \left( \xi_1, \xi_3 \right) \right), \,
    M \left( \xi_1 \; \middle| \; \xi_2 \right) $.
\end{enumerate}

\textit{Решение.}
$$A =
  \begin{bmatrix}
    1 & 2 & 1 \\
    2 & 6 & -1 \\
    1 & -1 & 12
  \end{bmatrix}$$

\begin{enumerate}[label=\alph*)]
  \item Начинаем со случайной величины $ \xi_1$.
  Запишем её как линейную комбинацию гауссового вектора
  $ \xi_1 =
    1 \cdot \xi_1 + 0 \cdot \xi_2 + 0 \cdot \xi_3$.
  Следовательно, $ \xi_1 \sim N \left( -1, 1 \right) $, где $-1$ --- это первый элемент $ \vec{a}$,
  а 1 --- элемент $a_{11}$ матрицы ковариации.

  Записываем плотность
  $$p_{ \xi_1} \left( x \right) =
    \frac{1}{ \sqrt{2 \pi }} \cdot e^{- \frac{ \left( x + 1 \right)^2}{2}}$$
  и характеристическую функцию $ \varphi_{ \xi_1} \left( t \right) = e^{-it - \frac{t^2}{2}}$.

  Переходим к вектору $ \left( \xi_1, \xi_2 \right) $.
  Это гауссовый вектор,
  потому что произвольная линейная комбинация
  $ \lambda_1 \xi_1 + \lambda_2 \xi_2 = \lambda_1 \xi_1 + \lambda_2 \xi_2 + 0 \cdot \xi_3$ ---
  это случайная величина, которая должна иметь нормальное распределение.
  Отсюда следует, что $ \left( \xi_1, \xi_2 \right) = \vec{ \xi }$ --- гауссовый вектор.

  $M \vec{ \xi } = \left( -1, 0 \right) $, а ковариационная матрица данного вектора ---
  это сужение исходной ковариационной матрицы на соответствующие вектора
  $$R =
    \begin{bmatrix}
      1 & 2 \\
      2 & 6
    \end{bmatrix}.$$

  Записываем характеристическую функцию и плотность.
  Матрица коавриации невырождена, так что плотность можем записать
  $$p_{ \left( \xi_1, \xi_2 \right) } \left( \vec{x} \right) =
    \frac{1}{ \left( 2 \pi \right)^{ \frac{3}{2}} \sqrt{2}} \cdot
    e^{- \frac{1}{2} \left( x_1 + 1 \, x_2 \right) \cdot
      \begin{bmatrix}
        3 & -1 \\
        -1 & \frac{1}{2}
      \end{bmatrix} \cdot
      \begin{bmatrix}
        x_1 + 1 \\
        x_2
      \end{bmatrix}
    }.$$
  Определитель этой матрицы $det \, R = 6 - 4 = 2$.
  Обратная матрица
  $$R^{-1} =
    \frac{1}{2} \cdot
    \begin{bmatrix}
      6 & -2 \\
      -2 & 1
    \end{bmatrix} =
    \begin{bmatrix}
      3 & -1 \\
      -1 & \frac{1}{2}
    \end{bmatrix}.$$
  Подставим полученное в выражение для плотности
  \begin{equation*}
    \begin{split}
      \frac{1}{ \left( 2 \pi \right)^{ \frac{3}{2}} \sqrt{2}} \cdot
      e^{- \frac{1}{2} \cdot
        \begin{bmatrix}
          x_1 + 1 & x_2
        \end{bmatrix} \cdot
        \begin{bmatrix}
          3 & -1 \\
          -1 & \frac{1}{2}
        \end{bmatrix} \cdot
        \begin{bmatrix}
          x_1 + 1 \\
          x_2
        \end{bmatrix}
      } = \\
      = \frac{1}{ \left( 2 \pi \right)^{ \frac{3}{2}} \sqrt{2}} \cdot
      exp \left\{
        - \frac{1}{4} \cdot
        \begin{bmatrix}
          x_1 + 6 - 2 \cdot x_2 & -2x_1 - 2 + 2x_2
        \end{bmatrix} \cdot
        \begin{bmatrix}
          x_1 + 1 \\
          x_2
        \end{bmatrix}
      \right\} = \\
      = \frac{1}{ \left( 2 \pi \right)^{ \frac{3}{2}} \sqrt{2}} \cdot
      exp \left\{
        - \frac{1}{4} \cdot
        \left[
          6 \, x_1 \left( x_1 + 1 \right) - 2x_1 \left( x_1 - 1 \right) - 2x_1 x_2 + 2x_2^2
        \right]
      \right\}.
    \end{split}
  \end{equation*}

  Для вектора $ \xi $ математическое ожидание равно $ \left( -1, 0, 2 \right) $,
  а матрица ковариаций совпадает с исходной;
  \item задача: выписать матрицу,
  с помощью которой получим вектор
  $$ \vec{ \eta } =
    \left( \eta_1, \eta_2, \eta_3 \right).$$
  В условии задачи дано, что
  $$A_{ \xi } =
    \begin{bmatrix}
      1 & 2 & 1 \\
      2 & 6 & -1 \\
      1 & -1 & 12
    \end{bmatrix},$$
  а $ \vec{m}_{ \xi } = \left( -1, 0, 2 \right) $.

  Посмотрим, с помощью какой матрицы получаются преобразования.
  $$ \begin{bmatrix}
      \eta_1 \\
      \eta_2 \\
      \eta_3
    \end{bmatrix} =
    \begin{bmatrix}
      1 & -1 & 0 \\
      1 & 2 & 3 \\
      0 & 0 & 1
    \end{bmatrix}
    \begin{bmatrix}
      \xi_1 \\
      \xi_2 \\
      \xi_3
    \end{bmatrix}.$$

  Это матрица $B$.
  Находим математическое ожидание вектора $ \eta $.
  Получаем
  $$ \vec{m}_{ \eta } =
    B \vec{m}_{ \xi } =
    \begin{bmatrix}
      1 & -1 & 0 \\
      1 & 2 & 3 \\
      0 & 0 & 1
    \end{bmatrix}
    \begin{bmatrix}
      -1 \\
      0 \\
      2
    \end{bmatrix} =
    \begin{bmatrix}
      -1 \\
      5 \\
      2
    \end{bmatrix}.$$

  Теперь ищем матрицу ковариации
  $$A_{ \eta } =
    BA_{ \xi } B^T =
    \begin{bmatrix}
      1 & -1 & 0 \\
      1 & 2 & 3 \\
      0 & 0 & 1
    \end{bmatrix}
    \begin{bmatrix}
      1 & 2 & 1 \\
      2 & 6 & -1 \\
      1 & -1 & 12
    \end{bmatrix}
    \begin{bmatrix}
      1 & 1 & 0 \\
      -1 & 2 & 0 \\
      0 & 3 & 1
    \end{bmatrix}.$$
  Перемножим две последние матрицы
  $$ \begin{bmatrix}
      1 & -1 & 0 \\
      1 & 2 & 3 \\
      0 & 0 & 1
    \end{bmatrix}
    \begin{bmatrix}
      1 & 2 & 1 \\
      2 & 6 & -1 \\
      1 & -1 & 12
    \end{bmatrix}
    \begin{bmatrix}
      1 & 1 & 0 \\
      -1 & 2 & 0 \\
      0 & 3 & 1
    \end{bmatrix} =
    \begin{bmatrix}
      1 & -1 & 0 \\
      1 & 2 & 3 \\
      0 & 0 & 1
    \end{bmatrix}
    \begin{bmatrix}
      -1 & 8 & 1 \\
      -4 & 11 & -1 \\
      2 & 35 & 12
    \end{bmatrix}.$$
  Перемножим матрицы
  $$ \begin{bmatrix}
      1 & -1 & 0 \\
      1 & 2 & 3 \\
      0 & 0 & 1
    \end{bmatrix}
    \begin{bmatrix}
      -1 & 8 & 1 \\
      -4 & 11 & -1 \\
      2 & 35 & 12
    \end{bmatrix} =
    \begin{bmatrix}
      -3 & -3 & 2 \\
      -3 & 135 & 35 \\
      2 & 35 & 12
    \end{bmatrix}.$$

  Эта матрица ковариаций, значит, она симметричная;
  \item случайная величина $ \eta_2$ имеет распределение Гаусса, как компонент гауссового вектора.
  Нужно указать параметры, то есть её математическое ожидание и дисперсию.
  $ \eta_2 \sim N \left( 5, 135 \right) $.
  У нас нецентрированная случайная величина.
  Значит, $ \eta_2 - 5 \sim N \left( 0, 135 \right) $.
  Поэтому $M \left( \eta_2 - 5 \right)^2 = 135$, потому что это её дисперсия.
  Раскрываем слева скобки,
  пользуемся линейностью математического ожидания и находим второй момент
  $M \eta_2^2 - 25M \eta_2 + 25 =
    135$.
  Математическое ожидание $ \eta_2$ мы знаем,
  выражаем второй момент $M \eta_2^2 = 10 c\dot 5 + 110 = 160$

  Третий момент этой случайной величины равен $M \left( \eta_2 - 5 \right)^3 = 0$.
  Так же раскрываем скобки слева $M \eta_2^3 - 15M \eta_2^2 + 75M \eta_2 - 125 = 0$,
  откуда $M \eta_2^3 = 15 * 160 - 75 * 5 + 125 = 2400 - 250 = 2150$.

  Четвёртый момент находится аналогично;
  \item если бы они были независимыми, ковариация была бы равна нулю.
  Это элемент матрицы $ \left( 1, 2 \right) $.
  Он равен $Cov \left( \eta_1, \eta_2 \right) = -3 \neq 0$.
  Отсюда следует, что случайные величины зависимы.

  Компопненты гауссового вектора независимы тогда и только тогда, когда они некоррелируемы;
  \item пользуемся теоремой о нормальной корреляции.

  Записываем, как в теореме,
  $M \left[ \xi_1, \left( \xi_2, \xi_3 \right) \right] =
    M \xi_1 +
    Cov \left[ \xi_1, \left( \xi_2, \xi_3 \right) \right] \cdot
    \left\{
      Cov \left[ \left( \xi_2, \xi_3 \right), \left( \xi_2, \xi_3 \right) \right]
    \right\}^{-1} \left[ \left( \xi_2, \xi_3 \right) - M \left( \xi_2, \xi_3 \right) \right]^T$.
  Подставляем
  \begin{equation*}
    \begin{split}
      M \xi_1 +
      Cov \left[ \xi_1, \left( \xi_2, \xi_3 \right) \right] \cdot
      \left\{
        Cov \left[ \left( \xi_2, \xi_3 \right), \left( \xi_2, \xi_3 \right) \right]
      \right\}^{-1}
      \left[ \left( \xi_2, \xi_3 \right) - M \left( \xi_2, \xi_3 \right) \right]^T = \\
      = -1 +
      \begin{bmatrix}
        2 & 1
      \end{bmatrix}
      \begin{bmatrix}
        6 & -1 \\
        -1 & 12
      \end{bmatrix}^{-1}
      \begin{bmatrix}
        \xi_2 - 0 \\
        \xi_3 - 2
      \end{bmatrix} = \\
      = -1 +
      \begin{bmatrix}
        2 & 1
      \end{bmatrix} \cdot \frac{1}{71}
      \begin{bmatrix}
        12 & 1 \\
        1 & 6
      \end{bmatrix}
      \begin{bmatrix}
        \xi_2 \\
        \xi_3 - 2
      \end{bmatrix} =
      -1 +
      \begin{bmatrix}
        25 & 8
      \end{bmatrix} \cdot \frac{1}{71}
      \begin{bmatrix}
        \xi_2 \\
        \xi_3 - 2
      \end{bmatrix} = \\
      = -1 + \frac{1}{71} \left( 25 \xi_2 + 8 \xi_3 - 16 \right)
    \end{split}
  \end{equation*}
  --- оценка $ \xi_1$ по вектору $ \left( \xi_2, \xi_3 \right)$.

  Аналогично
  $$M \left( \xi_1, \xi_2 \right) =
    M \xi_1 +
    Cov \left( \xi_1, \xi_2 \right) \left[ Cov \left( \xi_2, \xi_2 \right) \right]^{-1} \cdot
    \left( \xi_2 - M \xi_2 \right).$$
  Подставляем известные значения
  $$M \xi_1 +
    Cov \left( \xi_1, \xi_2 \right) \left[ Cov \left( \xi_2, \xi_2 \right) \right]^{-1} \cdot
    \left( \xi_2 - M \xi_2 \right) =
    -1 + 2 \cdot \frac{1}{6} \left( \xi_2 - 0 \right).$$
  Сократим
  $$-1 + 2 \cdot \frac{1}{6} \left( \xi_2 - 0 \right) =
    -1 + \frac{1}{3} \cdot \xi_2.$$
\end{enumerate}


\addcontentsline{toc}{section}{Домашнее задание}
\section*{Домашнее задание}

\subsubsection*{7.11}

\textit{Задание.}
Может ли матрица $A$ быть ковариационной матрицей гауссовского случайного вектора, если:
\begin{enumerate}[label=\alph*)]
  \item $A =
    \begin{bmatrix}
      1 & 1 & 0 \\
      1 & 1 & 0 \\
      0 & 0 & 2
    \end{bmatrix};$
  \item $A =
    \begin{bmatrix}
      1 & 2 & 1 \\
      2 & 5 & 0 \\
      1 & 0 & 5
    \end{bmatrix}.$
\end{enumerate}

\textit{Решение.}
\begin{enumerate}[label=\alph*)]
  \item Матрица квадратная, симметричная, на диагонали --- неотрицательные числа.
  Первый минор $M_1 = 1 \geq 0$, второй минор
  $$M_2 =
    \begin{vmatrix}
      1 & 1 \\
      1 & 1
    \end{vmatrix} =
    1 - 1 =
    0 \geq 0,$$
  третий минор
  $$M_3 =
    \begin{vmatrix}
      1 & 1 & 0 \\
      1 & 1 & 0 \\
      0 & 0 & 2
    \end{vmatrix} =
    0 \cdot
    \begin{vmatrix}
      1 & 1 \\
      0 & 0
    \end{vmatrix} - 0 \cdot
    \begin{vmatrix}
      1 & 1 \\
      0 & 0
    \end{vmatrix} + 2 \cdot
    \begin{vmatrix}
      1 & 1 \\
      1 & 1
    \end{vmatrix} =
    0 \geq
    0,$$
  значит матрица неотрицательно определённная,
  то есть может быть ковариационной матрицей гауссовского случайного вектора;
  \item матрица квадратная, симметричная, на диагонали --- неотрицательные числа.
  Первый минор $M_1 = 1 \geq 0$, второй минор
  $$M_2 =
    \begin{vmatrix}
      1 & 2 \\
      2 & 5
    \end{vmatrix} =
    5 - 4 =
    1 \geq
    0,$$
  третий минор
  $$M_3 =
    \begin{vmatrix}
      1 & 2 & 1 \\
      2 & 5 & 0 \\
      1 & 0 & 5
    \end{vmatrix} =
    1 \cdot
    \begin{vmatrix}
      2 & 5 \\
      1 & 0
    \end{vmatrix} - 0 \cdot
    \begin{vmatrix}
      1 & 2 \\
      1 & 0
    \end{vmatrix} + 5 \cdot
    \begin{vmatrix}
      1 & 2 \\
      2 & 5
    \end{vmatrix} =
    -5 + 5 \left( 5 - 4 \right) =
    0,$$
  значит матрица неотрицательно определённая,
  то есть может быть ковариационной матрицей гауссовского случайного вектора.
\end{enumerate}


\subsubsection*{7.12}

\textit{Задание.}
Пусть $ \left( \xi_1, \xi_2, \xi_3 \right) $ ---
гауссовский вектор со средним $ \left( 1, 2, 5 \right) $ и матрицей ковариаций из задачи 7.3 f).
\begin{enumerate}[label=\alph*)]
  \item Запишите плотность распределения и характеристическую функцию для вектора
  $ \left( \xi_1, \xi_2, \xi_3 \right) $.
  \item Найдите матрицу ковариаций и среднее для вектора $ \left( \eta_1, \eta_2, \eta_3 \right) $,
  где $ \eta_1 = \xi_1 + \xi_2, \, \eta_2 = \xi_2 + \xi_3, \, \eta_3 = \xi_1 + \xi_3$.
  \item Выясните, являются ли случайные величины $ \eta_2, \eta_3$ независимыми.
  \item Найдите условные математические ожидания
  $$M \left( \xi_2 \; \middle| \; \left( \xi_1, \xi_3 \right) \right), \,
    M \left( \xi_1 \; \middle| \; \xi_2 \right).$$
  \item Вычислите $M \eta_1^2, M \eta_1^3, M \eta_1^4$.
\end{enumerate}

\textit{Решение.}
\begin{enumerate}[label=\alph*)]
  \item $ \left( \xi_1, \xi_2, \xi_3 \right) = \vec{ \xi }$ ---
  гауссовский вектор с математическим ожиданием $M \vec{ \xi } = \left( 1, 2, 5 \right) $
  и ковариационной матрицей
  $$A =
    \begin{bmatrix}
      1 & 2 & 1 \\
      2 & 5 & 0 \\
      1 & 0 & 10
    \end{bmatrix}.$$

  Записываем характеристическую функцию и плотность.

  $$det \, A =
    \begin{vmatrix}
      1 & 2 & 1 \\
      2 & 5 & 0 \\
      1 & 0 & 10
    \end{vmatrix} =
    1 \cdot
    \begin{vmatrix}
      2 & 5 \\
      1 & 0
    \end{vmatrix} - 0 \cdot
    \begin{vmatrix}
      1 & 2 \\
      1 & 0
    \end{vmatrix} + 10 \cdot
    \begin{vmatrix}
      1 & 2 \\
      2 & 5
    \end{vmatrix} =
    -5 + 10 \left( 5 - 4 \right) =
    5.$$
  Матрица ковариаций невырождена, так что может записать
  $$p_{ \left( \xi_1, \xi_2, \xi_3 \right) } \left( \vec{x} \right) =
    \frac{1}{ \left( 2 \pi \right)^{ \frac{3}{2}}} \cdot \frac{1}{ \sqrt{5}} \cdot
    e^{- \frac{1}{2} \cdot
      \begin{bmatrix}
        x_1 - 1 & x_2 - 2 & x_3 - 5
      \end{bmatrix} \cdot A^{-1} \cdot
      \begin{bmatrix}
        x_1 - 1 \\
        x_2 - 2 \\
        x_3 - 5
      \end{bmatrix}}.$$
  Найдём обратную матрицу к матрице ковариаций
  $$A^{-1} =
    \frac{1}{5} \cdot
    \begin{bmatrix}
      50 & -10 & -5 \\
      -10 & 9 & 2 \\
      -5 & 2 & 1
    \end{bmatrix}.$$
  Перемножив вектора и матрицы в степени экспоненты, получим
  \begin{equation*}
    \begin{split}
      \frac{1}{ \left( 2 \pi \right)^{ \frac{3}{2}}} \cdot \frac{1}{ \sqrt{5}} \cdot
      e^{- \frac{1}{2} \cdot
        \begin{bmatrix}
          x_1 - 1 & x_2 - 2 & x_3 - 5
        \end{bmatrix} \cdot A^{-1} \cdot
        \begin{bmatrix}
          x_1 - 1 \\
          x_2 - 2 \\
          x_3 - 5
        \end{bmatrix}} = \\
      = \frac{1}{ \left( 2 \pi \right)^{ \frac{3}{2}} \sqrt{5}} \cdot
      e^{50x_1^2 + 9x_2^2 + x_3^2 - 40x_1 x_2 - 10x_1 x_3 + 4x_2 x_3 + 30x_1 - 16x_2 - 8x_3 + 21}.
    \end{split}
  \end{equation*}

  Запишем характеристическую функцию
  $$ \varphi_{ \vec{ \xi }} \left( \vec{ \lambda } \right) =
    exp \left\{
      i \left( \vec{ \lambda }, M \vec{ \xi } \right) -
      \frac{1}{2} \cdot \left( A \vec{ \lambda }, \vec{ \lambda }
    \right) \right\}.$$
\end{enumerate}
