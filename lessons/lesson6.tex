\addcontentsline{toc}{chapter}{Занятие 6. Теорема Колмогорова про улучшение оценок.
                              Неравенство Рао-Крамера}
\chapter*{Занятие 6. Теорема Колмогорова про улучшение оценок. Неравенство Рао-Крамера}

\addcontentsline{toc}{section}{Контрольные вопросы и задания}
\section*{Контрольные вопросы и задания}

\subsubsection*{Приведите определение достаточной статистики.}

Статистика $T$ называется достаточной для параметра $ \theta $,
если условное распределение при известном $T$ не зависит от параметра $ \theta $.

\subsubsection*{Сформулируйте теорему про характеризацию достаточной статистики.}

Пусть $x_1, \dotsc, x_n$ ---
выборка из распределения с плотностью
$$p \left( x, \theta \right), \,
  \theta \in \Theta.$$

Статистика $T$ является достаточной тогда и только тогда,
когда функция правдоподобия $L \left( \vec{x}, \theta \right) $ допускает факторизацию,
то есть может быть представлена произведением двух функций следующего вида
$$L \left( \vec{x}, \theta \right) =
  h \left( T, \theta \right) \cdot g \left( \vec{x} \right).$$

\subsubsection*{Сформулируйте теорему Колмогорова про улучшение
                оценки с помощью достаточной статистики.}

Оптимальная оценка единственная (в том случае, когда она существует).

\subsubsection*{Что называется количеством информации Фишера?}

$$D_{ \theta } U \left( \vec{x}, \theta \right) =
  nD_{ \theta } \left(
    \frac{ \partial }{ \partial \theta } ln \, p \left( x, \theta \right)
  \right) =
  nI_0,$$
где $nI_0$ --- количество информации Фишера.

\subsubsection*{Запишите неравенство Рао-Крамера.}

Пусть $ \hat{ \theta }$ --- несмещённая оценка для параметра $ \theta $.
Тогда
$$ \forall \theta \in \Theta: \,
  D_{ \theta } \hat{ \theta } \geq \frac{1}{nI_0}.$$
Как угодно лучшую оценку взять нельзя.

\subsubsection*{Какая оценка называется эффективной?}

Если $ \hat{ \theta }$ такова, что $ \hat{ \theta }$ --- несмещённая и
$$D_{ \theta } \hat{ \theta } =
  \frac{1}{nI_0}, \,
  \theta \in \Theta,$$
то $ \hat{ \theta }$ называется эффективной оценкой.

\subsubsection*{Приведите определение экспоненциальной семьи распределений.}

\addcontentsline{toc}{section}{Аудиторные задачи}
\section*{Аудиторные задачи}

\subsubsection*{6.3}

\textit{Задание.}
Пусть $X_1, \dotsc, X_n$ ---
выборка из равномерного распределения на отрезке $ \left[ 0, \theta \right].$
Найдите несмещённую оценку неизвестного параметра
$ \tau \left( \theta, y \right) =
  P \left( X_1 > y \right) $
и улучшите её усреднением по достаточной для параметра $ \theta $ статистике.

\textit{Решение.} $X_{ \left( n \right) }$ --- достаточная статистика для $ \theta $.

Нужно найти $ \hat{ \tau }$ из условия, что она была бы несмещённой,
что
$$M \hat{ \tau } =
  \tau =
  P \left( X_1 > y \right).$$
Берём в качестве $ \hat{ \tau } = \mathbbm{1} \left\{ X_1 > y \right\} $ ---
это несмещённая оценка для $ \tau $.
Теперь улучшаем эту оценку.
$ \tau^* =
  M \left( \hat{ \tau } \; \middle| \; X_{ \left( n \right) } \right) =
  M \left\{ \mathbbm{1} \left\{ X_1 < y \right\} \; \middle| \; X_{ \left( n \right) } \right\}.$
Индикатор может принимать значения 0 и 1,
значит
\begin{equation*}
  \begin{split}
    M \left\{
      \mathbbm{1} \left\{ X_1 < y \right\} \; \middle| \; X_{ \left( n \right) }
    \right\} = \\
    = 0 \cdot
    P \left(
      \mathbbm{1} \left\{ X_1 > y \right\} = 0 \; \middle| \; X_{ \left( n \right) }
    \right) +
    1 \cdot
    P \left( \mathbbm{1} \left\{ X_1 > y \right\} = 1 \; \middle| \; X_{ \left( n \right) } \right).
  \end{split}
\end{equation*}
Первое слагаемое пропадает
\begin{equation*}
  \begin{split}
    0 \cdot
    P \left(
      \mathbbm{1} \left\{ X_1 > y \right\} = 0 \; \middle| \; X_{ \left( n \right) }
    \right) +
    1 \cdot
    P \left(
      \mathbbm{1} \left\{ X_1 > y \right\} = 1 \; \middle| \; X_{ \left( n \right) }
    \right) = \\
    = P \left( X_1 > y \; \middle| X_{ \left( n \right) } \right) =
    f \left( X_{ \left( n \right) } \right).
  \end{split}
\end{equation*}
Ищем $f \left( z \right) = P \left( X_1 > y \; \middle| \; X_{ \left( n \right) } = z \right).$
Выборка имеет равномерное распределение, то есть распределение, которое имеет плотность.
Вероятность попадания в точку равна нулю
$$ P \left( X_1 > y \; \middle| \; X_{ \left( n \right) } = z \right) =
  \lim \limits_{h \to 0}
    P \left\{ X_1 > y \; \middle| \; X_{ \left( n \right) } \in \left[ z, z + h \right] \right\}.$$
Воспользуемся определением условной вероятности
$$ \lim \limits_{h \to 0}
    P \left\{ X_1 > y \; \middle| \; X_{ \left( n \right) } \in \left[ z, z + h \right] \right\} =
  \lim \limits_{h \to 0}
    \frac{P \left\{ X_1 > y, X_{ \left( n \right) } \in \left[ z, z + h \right] \right\} }{P \left\{ X_{ \left( n \right) } \in \left[ z, z + h \right] \right\} }.$$
Это нужно рассматривать при $y < z$.
Разбиваем на разность двух вероятностей в числителе и знаменателе
\begin{equation*}
  \begin{split}
    \lim \limits_{h \to 0}
      \frac{P \left\{ X_1 > y, X_{ \left( n \right) } \in \left[ z, z + h \right] \right\} }{P \left\{ X_{ \left( n \right) } \in \left[ z, z + h \right] \right\} } = \\
    = \lim \limits_{h \to 0} \left[
      \frac{P \left\{ X_1 > y, X_{ \left( n \right) } \leq z + h \right\} }{P \left\{ X_{ \left( n \right) } \leq z + h \right\} - P \left\{ X_{ \left( n \right) } \leq z \right\} } -
      \frac{P \left\{ X_1 > y, X_{ \left( n \right) } \leq z \right\} }{P \left\{ X_{ \left( n \right) } \leq z + h \right\} - P \left\{ X_{ \left( n \right) } \leq z \right\} }
    \right].
  \end{split}
\end{equation*}
Переходим к функции распределения выборки
\begin{equation*}
  \begin{split}
    \lim \limits_{h \to 0} \left[
      \frac{P \left\{ X_1 > y, X_{ \left( n \right) } \leq z + h \right\} }{P \left\{ X_{ \left( n \right) } \leq z + h \right\} - P \left\{ X_{ \left( n \right) } \leq z \right\} } -
      \frac{P \left\{ X_1 > y, X_{ \left( n \right) } \leq z \right\} }{P \left\{ X_{ \left( n \right) } \leq z + h \right\} - P \left\{ X_{ \left( n \right) } \leq z \right\} }
    \right] = \\
    = \lim \limits_{h \to 0} \left\{
      \frac{ \left[ F \left( z + h \right) - F \left( y \right) \right] \left[ F \left( z + h \right) \right]^{n - 1}}{ \left[ F \left( z + h \right) \right]^n - \left[ F \left( z \right) \right]^n} -
      \frac{ \left[ F \left( z \right) - F \left( y \right) \right] \left[ F \left( z \right) \right]^{n - 1}}{ \left[ F \left( z + h \right) \right]^n - \left[ F \left( z \right) \right]^n}
    \right\}.
  \end{split}
\end{equation*}

Знаменатель и числитель стремятся к нулю.
Дифференцируем по $h$ числитель и знаменатель.
Это правило Лопиталя
\begin{equation*}
  \begin{split}
    \lim \limits_{h \to 0} \left\{
      \frac{ \left[ F \left( z + h \right) - F \left( y \right) \right] \left[ F \left( z + h \right) \right]^{n - 1}}{ \left[ F \left( z + h \right) \right]^n - \left[ F \left( z \right) \right]^n} -
      \frac{ \left[ F \left( z \right) - F \left( y \right) \right] \left[ F \left( z \right) \right]^{n - 1}}{ \left[ F \left( z + h \right) \right]^n - \left[ F \left( z \right) \right]^n}
    \right\} = \\
    = \lim \limits_{h \to 0} \left\{
      \frac{p \left( z + h \right) \left[ F \left( z + h \right) \right]^{n - 1}}{n \left[ F \left( z + h \right) \right]^{n - 1} p \left( z + h \right) } +
      \frac{ \left( n + 1 \right) \left[ F \left( z + h \right) \right]^{n - 2} p \left( z + h \right) \left[ F \left( z + h \right) - F \left( y \right) \right] }{n \left[ F \left( z + h \right) \right]^{n - 1} p \left( z + h \right) }
    \right\} = \\
    = \lim \limits_{h \to 0}
      \frac{F \left( z + h \right) + \left( n - 1 \right) \left[ F \left( z + h \right) - F \left( y \right) \right] }{nF \left( z + h \right) }.
  \end{split}
\end{equation*}
Переходим к пределу
$$ \lim \limits_{h \to 0}
    \frac{F \left( z + h \right) + \left( n - 1 \right) \left[ F \left( z + h \right) - F \left( y \right) \right] }{nF \left( z + h \right) } =
  \frac{F \left( z \right) + \left( n + 1 \right) \left[ F \left( z \right) - F \left( y \right) \right] }{nF \left( z \right) }.$$
Приводим подобные
$$ \frac{F \left( z \right) + \left( n + 1 \right) \left[ F \left( z \right) - F \left( y \right) \right] }{nF \left( z \right) } =
  \frac{nF \left( z \right) - \left( n - 1 \right) F \left( y \right) }{nF \left( z \right) }.$$
Почленно поделим числитель на знаменатель
$$ \frac{nF \left( z \right) - \left( n - 1 \right) F \left( y \right) }{nF \left( z \right) } =
  1 - \frac{n - 1}{n} \cdot \frac{F \left( y \right) }{F \left( z \right) }.$$
Подставляем значения функции равномерного распределения на отрезке $ \left[ 0, \theta \right] $.
Получаем
$$1 - \frac{n - 1}{n} \cdot \frac{F \left( y \right) }{F \left( z \right) } =
  1 - \frac{n - 1}{n} \cdot \frac{y}{z}.$$

Окончательно
$$f \left( X_{ \left( n \right) } \right) =
  1 - \frac{n - 1}{n} \cdot \frac{y}{X_{ \left( n \right) }}.$$

\subsubsection*{6.4}

\textit{Задание.}
Пусть $X_1, \dotsc, X_n$ --- выборка из распределения Пуассона с параметром $ \lambda $.
В качестве оценки параметра $ \theta = e^{- \lambda }$ рассматривают статистику
$ \hat{ \theta } =
  \mathbbm{1} \left\{ X_1 = 0 \right\} $.
Вычислите смещение $b_n \left( \theta \right) = M \hat{ \theta } - \theta $
этой оценки и улучшите её усреднением по достаточной статистике для параметра
$ \theta $ статистикой.

\textit{Решение.} Неизвестный параметр --- это $e^{- \lambda } = \theta $.

Ищем смещение
$M \hat{ \theta } =
  M \mathbbm{1} \left\{ X_1 = 0 \right\} =
  P \left\{ X_1 = 0 \right\} =
  e^{- \lambda } =
  \theta $,
значит, смещение $b_n \left( \theta \right) = 0$.
Это несмещённая оценка.

Займёмся поиском достаточной статистики
$$L \left( \vec{X}, \lambda \right) =
  \prod \limits_{i = 1}^n \frac{ \lambda^{X_i}}{X_i!} \cdot e^{- \lambda } =
  \frac{ \lambda^{n \overline{X}}}{X_1! \dotsc X_n!} \cdot e^{- \lambda n} =
  \frac{1}{X_1! \dotsc X_n!} \cdot \lambda^{n \overline{X}} e^{- \lambda n}.$$

Вывод: $ \overline{X}$ --- достаточная статистика для $ \lambda $, а значит и для $ \theta $,
как функции от $ \lambda $.

Нудно найти условное математическое ожидание
$M \left( \hat{ \theta } \; \middle| \; \overline{X} \right) =
  f \left( \overline{X} \right) $.
Начнём с
$f \left( y \right) =
  M \left( \hat{ \theta } \; \middle| \; \overline{X} = y \right) =
  M \left( \mathbbm{1} \left\{ X_1 = 0 \right\} \; \middle| \; \overline{X} = y \right) $.
Индикатор --- это дискретная случайная величина, которая принимает 2 значения
$$M \left( \mathbbm{1} \left\{ X_1 = 0 \right\} \; \middle| \; \overline{X} = y \right) =
  1 \cdot P \left( X_1 = 0 \; \middle| \; \overline{X} = y \right) =
  \frac{P \left( X_1 = 0, \sum \limits_{i = 1}^n X_i = ny \right) }{P \left( \sum \limits_{i = 1}^n X_i = ny \right) }.$$
В числителе стоит случайное событие $X_1 = 0$.
Оно означает, что суммировать можно от двух
$$ \frac{P \left( X_1 = 0, \sum \limits_{i = 1}^n X_i = ny \right) }{P \left( \sum \limits_{i = 1}^n X_i = ny \right) } =
  \frac{P \left( X_1 = 0 \right) P \left( \sum \limits_{i = 2}^n X_i = ny \right) }{P \left( \sum \limits_{i = 1}^n X_i = ny \right) }.$$
Сумма независимых пуассоновских случайных величин имеет распределение Пуассона с параметром,
который равен сумме параметров
$$ \frac{P \left( X_1 = 0 \right) P \left( \sum \limits_{i = 2}^n X_i = ny \right) }{P \left( \sum \limits_{i = 1}^n X_i = ny \right) } =
  \frac{e^{- \lambda } \cdot \frac{ \left( \left( n - 1 \right) \lambda \right)^{ny}}{ \left( ny \right)!} \cdot e^{- \lambda \left( n - 1 \right) }}{ \frac{ \left( n \lambda \right)^{ny}}{ \left( ny \right)!} \cdot e^{- \lambda n}} =
  \left( \frac{n - 1}{n} \right)^{ny}.$$

Чтобы записать ответ, нужно вместо $y$ записать $ \overline{X}$.
Получим
$$ \left( \frac{n - 1}{n} \right)^{n \overline{X}}.$$
Когда $n \to \infty $, эта оценка стремится к $e^{- \overline{X}}$.

\subsubsection*{6.5}

\textit{Задание.}
Пользуясь неравенством Рао-Крамера, выясните,
является ли эффективной оценка $ \overline{X}$ параметра $p$ распределения Бернулли.

\textit{Решение.} $X_1, \dotsc, X_n$ --- выборка.

Несмещённой оценкой для параметра является $ \hat{p} = \overline{X}$.
Формально в этом убедимся.
Итак,
$$M \hat{p} =
  M \overline{X} =
  \frac{1}{n} \cdot M \sum \limits_{i = 1}^n X_i.$$
Все случайные величины одинаково распределены, следовательно, все математические ожидания совпадают
$$ \frac{1}{n} \cdot M \sum \limits_{i = 1}^n X_i =
  \frac{1}{n} \cdot n MX_1 =
  MX_1 =
  p.$$

Ищем дисперсию
$$D \hat{p} =
  D \overline{X} =
  D \left( \frac{1}{n} \sum \limits_{i = 1}^n X_i \right) =
  \frac{1}{n^2} \cdot D \sum \limits_{i = 1}^n X_i.$$
Дисперсии равны.
Случайные величины независимы, следовательно, дисперсия суммы --- это сумма дисперсий
$$ \frac{1}{n^2} \cdot D \sum \limits_{i = 1}^n X_i =
  \frac{1}{n^2} \cdot nDX_1 =
  \frac{1}{n} \cdot p \left( 1 - p \right).$$

Сначала нужна функция правдоподобия для одного наблюдения
$$L \left( X_1, p \right) =
  p^{X_1} \left( 1 - p \right)^{1 - X_1}.$$
Логарифмируем
$ln \, L \left( X_1, p \right) =
  X_1 \, ln \, p + \left( 1 - p \right) ln \left( 1 - p \right) $.
Ищем первую производную
$$ \frac{ \partial }{ \partial p} ln \, L \left( X_1, p \right) =
  \frac{X_1}{p} - \frac{1 - X_1}{1 - p}.$$
Ищем вторую производную
$$ \frac{ \partial^2}{ \partial p^2} ln \, L \left( X_1, p \right) =
  - \frac{X_1}{p^2} - \frac{1 - X_1}{ \left( 1 -p \right)^2}.$$
Пишем количество информации.
Берём математическое ожидание со знаком <<минус>>
$$I \left( \theta \right) =
  M \left( \frac{X_1}{p} + \frac{1 - X_1}{ \left( 1 - p \right)^2} \right) =
  \frac{1}{p} + \frac{1 - p}{ \left( 1 - p \right)^2} =
  \frac{1}{p} + \frac{1}{1 - p}.$$
Приводим к общему знаменателю
$$ \frac{1}{p} + \frac{1}{1 - p} =
  \frac{1 - p + p}{p \left( 1 - p \right) } =
  \frac{1}{p \left( 1 - p \right) }.$$

Ищем обратную величину, делённую на $n$.
Получаем
$$ \frac{1}{nI \left( \theta \right) } =
  \frac{1}{n \left[ p \left( 1 - p \right) \right]^{-1}} =
  \frac{p \left( 1 - p \right) }{n} =
  D \hat{p},$$
следовательно, $ \hat{p}$ --- эффективная оценка параметра $p$.

\addcontentsline{toc}{section}{Домашнее задание}
\section*{Домашнее задание}

\subsubsection*{6.10}

\textit{Задание.}
Пусть $X_1, \dotsc, X_n$ ---
выборка из нормального распределения с параметрами $ \left( a, 1 \right) $.
Улучшите оценку $ \hat{a} = X_1$ усреднением по фиксированному значению достаточной
статистики $ \overline{X}$.
Найдите распределение, математическое ожидание и дисперсию улучшенной оценки.

\textit{Решение.} Улучшаем оценку
$$a^* =
  M \left( \hat{a} \; \middle| \; \overline{X} \right) =
  M \left( X_1 \; \middle| \; \overline{X} \right) =
  \frac{1}{n} \sum \limits_{i = 1}^n M \left( X_i \; \middle| \; \overline{X} \right) =
  M \left( \frac{1}{n} \sum \limits_{i = 1}^n X_i \; \middle| \; \overline{X} \right).$$
Запишем через выборочное среднее
$$M \left( \frac{1}{n} \sum \limits_{i = 1}^n X_i \; \middle| \; \overline{X} \right) =
  M \left( \overline{X} \; \middle| \; \overline{X} \right) =
  \overline{X}.$$

Математическое ожидание равно
$$Ma^* =
  M \overline{X} =
  M \left( \frac{1}{n} \sum \limits_{i = 1}^n X_i \right) =
  \frac{1}{n} \sum \limits_{i = 1}^n MX_i =
  \frac{1}{n} \cdot na =
  a,$$
дисперсия ---
$$Da^* =
  D \left( \frac{1}{n} \sum \limits_{i = 1}^n X_i \right) =
  \frac{1}{n^2} \cdot n DX_1 =
  \frac{1}{n} \cdot 1 =
  \frac{1}{n}.$$

Она имеет нормальное распределение
$$a^* \sim
  N \left( a, \frac{1}{n} \right).$$

Так как $Ma^* = a$, то оценка несмещённая.

\subsubsection*{6.11}

\textit{Задание.}
Пусть $X_1, \dotsc, X_n$ --- выборка из распределения Пуассона с параметром $ \lambda $.
В качестве оценки параметра $ \theta = e^{- \lambda }$ рассматривают статистику
$$ \hat{ \theta } =
  \overline{ \mathbbm{1} \left\{ X = 0 \right\} } =
  \frac{1}{n} \sum \limits_{i = 1}^n \mathbbm{1} \left\{ X_i = 0 \right\}.$$
Вычислите смещение $b_n \left( \theta \right) = M \hat{ \theta } - \theta $ этой оценки и выясните,
является ли она эффективной.

\textit{Решение.}
$$M \hat{ \theta } =
  M \left( \frac{1}{n} \sum \limits_{i = 1}^n \mathbbm{1} \left\{ X_i = 0 \right\} \right) =
  \frac{1}{n} M \left( \sum \limits_{i = 1}^n \mathbbm{1} \left\{ X_i = 0 \right\} \right) =
  \frac{1}{n} \cdot \sum \limits_{i = 1}^n P \left( X_i = 0 \right).$$
Подставляем значение вероятности для распределения Пуассона
$$ \frac{1}{n} \cdot \sum \limits_{i = 1}^n P \left( X_i = 0 \right) =
  \frac{1}{n} \cdot \sum \limits_{i = 1}^n \frac{ \lambda^0}{0!} \cdot e^{- \lambda } =
  \frac{1}{n} \cdot e^{- \lambda } \cdot n =
  e^{- \lambda }.$$

Подставляем полученное значение в формулу для смещения
$$b_n \left( \theta \right) =
  M \hat{ \theta } - \theta =
  e^{- \lambda } - e^{- \lambda } =
  0.$$
