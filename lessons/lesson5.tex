\addcontentsline{toc}{chapter}{Занятие 5. Достаточные статистики}
\chapter*{Занятие 5. Достаточные статистики}

\addcontentsline{toc}{section}{Контрольные вопросы и задания}
\section*{Контрольные вопросы и задания}

\subsubsection*{Приведите определение условного распределения, определение достаточной статистики.}

$P \left( \xi \in \Delta \; \middle| \; \mathcal{F'} \right) =
  M \left[ \mathbbm{1}_{ \Delta } \left( \xi \right) \; \middle| \; \mathcal{F'} \right] $.

Статистика $T$ называется достаточной для параметра $ \theta $,
если условное распределение при известном $T$ не зависит от параметра $ \theta $.

\subsubsection*{Сформулируйте теорему про характеризацию достаточной статистики.}

Пусть $x_1, \dotsc, x_n$ ---
выборка из распределения с плотностью
$$p \left( x, \theta \right), \,
  \theta \in \Theta.$$

Статистика $T$ является достаточной тогда и только тогда,
когда функция правдоподобия $L \left( \vec{x}, \theta \right) $ допускает факторизацию,
то есть может быть представлена произведением двух функций следующего вида
$$L \left( \vec{x}, \theta \right) =
  h \left( T, \theta \right) \cdot g \left( \vec{x} \right).$$

\addcontentsline{toc}{section}{Аудиторные задачи}
\section*{Аудиторные задачи}

\subsubsection{5.3}

\textit{Задание.} Пусть $X_1, \dotsc, X_n$ --- выборка из распределения Бернулли с параметром $p$.
Выясните, является ли $ \overline{X}$ достаточной статистикой для параметра $p$.

\textit{Решение.} Записываем условное распределение.

Пусть $k_i = 0$ или $1$.

По определению условной вероятности
\begin{equation*}
  \begin{split}
    P \left\{ \left. X_1 = k_1, X_2 = k_2, \dotsc, X_n = k_n \right| \overline{X} = y \right\} = \\
    = \frac{P \left\{ X_1 = k_1, X_2 = k_2, \dotsc, X_n = k_n, \overline{X} = y \right\} }{P \left\{ \overline{X} = y \right\} }.
  \end{split}
\end{equation*}
Выборочное среднее $ \overline{X}$ выражаем через сумму
\begin{equation*}
  \begin{split}
    \frac{P \left\{ X_1 = k_1, X_2 = k_2, \dotsc, X_n = k_n, \overline{X} = y \right\} }{P \left\{ \overline{X} = y \right\} } = \\
    = \frac{P \left\{ X_1 = k_1, X_2 = k_2, \dotsc, X_n = k_n, \sum \limits_{i = 1}^n X_i = ny \right\} }{P \left\{ \sum \limits_{i = 1}^n X_i = ny \right\} }.
  \end{split}
\end{equation*}
Все $X_i$ --- независимы, следовательно, будет произведение вероятностей событий
\begin{equation*}
  \begin{split}
    \frac{P \left\{ X_1 = k_1, X_2 = k_2, \dotsc, X_n = k_n, \sum \limits_{i = 1}^n X_i = ny \right\} }{P \left\{ \sum \limits_{i = 1}^n X_i = ny \right\} } = \\
    = \frac{ \mathbbm{1} \left\{ \sum \limits_{i = 1}^n k_i = ny \right\} P \left\{ X_1 = k_1 \right\} \cdot \dotsc \cdot P \left\{ X_n = k_n \right\} }{P \left\{ \sum \limits_{i = 1}^n X_i = ny \right\} }.
  \end{split}
\end{equation*}
Сумма распределена по биномиальному распределению с параметрами $n, p$.
Подставляем значения вероятностей
\begin{equation*}
  \begin{split}
    \frac{ \mathbbm{1} \left\{ \sum \limits_{i = 1}^n k_i = ny \right\} P \left\{ X_1 = k_1 \right\} \cdot \dotsc \cdot P \left\{ X_n = k_n \right\} }{P \left\{ \sum \limits_{i = 1}^n X_i = ny \right\} } = \\
    = \frac{ \mathbbm{1} \left\{ \sum \limits_{i = 1}^n k_i = ny \right\} p^{k_1} \left( 1 - p \right)^{1 - k_1} \cdot \dotsc \cdot p^{k_n} \left( 1 - p \right)^{1 - k_n}}{C_n^{ny} p^{ny} \left( 1 - p \right)^{n + ny}}.
  \end{split}
\end{equation*}
Воспользуемся индикатором
\begin{equation*}
  \begin{split}
    \frac{ \mathbbm{1} \left\{ \sum \limits_{i = 1}^n k_i = ny \right\} \cdot p^{k_1} \left( 1 - p \right)^{1 - k_1} \cdot \dotsc \cdot p^{k_n} \left( 1 - p \right)^{1 - k_n}}{C_n^{ny} p^{ny} \left( 1 - p \right)^{n + ny}} = \\
    = \frac{ \mathbbm{1} \left\{ \sum \limits_{i = 1}^n k_i = ny \right\} \cdot p^{ny} \left( 1 - p \right)^{n - ny}}{C_n^{ny} p^{ny} \left( 1 - p \right)^{n - ny}}.
  \end{split}
\end{equation*}
Всё, что связано с $p$, пропадает
$$ \frac{ \mathbbm{1} \left\{ \sum \limits_{i = 1}^n k_i = ny \right\} \cdot p^{ny} \left( 1 - p \right)^{n - ny}}{C_n^{ny} p^{ny} \left( 1 - p \right)^{n - ny}} =
  \frac{ \mathbbm{1} \left\{ \sum \limits_{i = 1}^n k_i = ny \right\} }{C_n^{ny}}.$$

Зависимости от $p$ нет.
Отсюда следует, что $ \overline{X}$ --- достаточная статистика.

\subsubsection{5.4}

\textit{Задание.}
Пусть $X_1, \dotsc, X_n$ --- выборка из распределения Пуассона с параметром $ \lambda $.
Найдите условное распределение выборки при условии
$$X_1 + \dotsc + X_n = k.$$
Выясните, является ли $ \overline{X}$ достаточной статистикой для параметра $ \lambda $.

\textit{Решение.} Это дискретное распределение
\begin{equation*}
  \begin{split}
    P \left\{ X_1 = k_1, \dotsc, X_n = k_n \; \middle| \; \sum \limits_{i = 1}^n X_i = k \right\} = \\
    \frac{P \left\{ X_1 = k_1, \dotsc, X_n = k_n, \sum \limits_{i = 1}^n X_i = k \right\} }{P \left\{ \sum \limits_{i = 1}^n X_i = k \right\} }.
  \end{split}
\end{equation*}
Случайные величины $X_i$ --- независимы
\begin{equation*}
  \begin{split}
    \frac{P \left\{ X_1 = k_1, \dotsc, X_n = k_n, \sum \limits_{i = 1}^n X_i = k \right\} }{P \left\{ \sum \limits_{i = 1}^n X_i = k \right\} } = \\
    \frac{ \mathbbm{1} \left\{ \sum \limits_{i = 1}^n k_i = k \right\} P \left\{ X_1 = k_1 \right\} \cdot \dotsc \cdot P \left\{ X_n = k_n \right\} }{P \left\{ \sum \limits_{i = 1}^n X_i = k \right\} }.
  \end{split}
\end{equation*}
Имеем распределение Пуассона.
Сумма независимых случайных величин имеет распределение Пуассона с параметром $ \lambda n$.
Подставляем значения вероятностей
\begin{equation*}
  \begin{split}
    \frac{ \mathbbm{1} \left\{ \sum \limits_{i = 1}^n k_i = k \right\} P \left\{ X_1 = k_1 \right\} \cdot \dotsc \cdot P \left\{ X_n = k_n \right\} }{P \left\{ \sum \limits_{i = 1}^n X_i = k \right\} } = \\
    = \mathbbm{1} \left\{ \sum \limits_{i = 1}^n k_i = k \right\} \cdot
    \frac{ \frac{ \lambda^{k_1}}{k_1!} \cdot e^{- \lambda } \cdot \dotsc \cdot \frac{ \lambda^{k_n}}{k_n!} \cdot e^{- \lambda }}{ \frac{ \left( \lambda n \right)^k}{k!} \cdot e^{- \lambda }} =
    \frac{ \mathbbm{1} \left\{ \sum \limits_{i = 1}^n k_i = k \right\} k!}{k_1! \dotsc k_n! n^k}.
  \end{split}
\end{equation*}

Видим, что нет зависимости от $ \lambda $, следовательно, выборочное среднее $ \overline{X}$ ---
достаточная статистика для неизвестного $ \lambda $.

\subsubsection{5.5}

\textit{Задание.}
Пусть $X_1, \dotsc X_n$ ---
выборка из нормального распределение со средним $a$ и единичной дисперсией.
Найдите условное совместное распределение выборки при условии $X_1 + \dotsc + X_n = y$.
Выясните, является ли $ \overline{X}$ достаточной статистикой для параметра $a$.

\textit{Решение.} Нужно записать функцию правдоподобия
$$L \left( X_1, \dotsc, X_n, a \right) =
  \prod \limits_{i = 1}^n \frac{1}{ \sqrt{2 \pi }} \cdot e^{ \frac{- \left( X_i - a \right)^2}{2}} =
  \frac{1}{ \left( \sqrt{2 \pi } \right)^n} \cdot
  e^{- \sum \limits_{i = 1}^n \frac{ \left( X_i - a \right)^2}{2}}.$$
Откроем квадрат и запишем в статистических обозначениях
$$ \frac{1}{ \left( \sqrt{2 \pi } \right)^n} \cdot
  e^{- \sum \limits_{i = 1}^n \frac{ \left( X_i - a \right)^2}{2}} =
  \frac{1}{ \left( \sqrt{2 \pi } \right)^n} \cdot
  e^{- \frac{n \overline{X^2}}{2} an \overline{X} - \frac{a^2 n}{2}} =
  \frac{1}{ \left( \sqrt{2 \pi } \right)^n} \cdot e^{- \frac{n \overline{X^2}}{2}} \cdot
  e^{an \overline{X} - \frac{a^2 n}{2}},$$
где
$$ \frac{1}{ \left( \sqrt{2 \pi } \right)^n} \cdot e^{- \frac{n \overline{X^2}}{2}} =
  h \left( X_1, \dotsc, X_n \right), \,
  e^{an \overline{X} - \frac{a^2 n}{2}} = g \left( a, \overline{X} \right).$$

Предьявляем функции, о которых идёт речь в теореме.

По теореме про характеризацию достаточной статистики $ \overline{X}$ --- достаточная статистика.

\subsubsection{5.6}

\textit{Задание.}
Пусть $X_1, \dotsc, X_n$ ---
выборка из нормального распределения с нулевым средним и дисперсией $ \sigma^2$.
Найдите достаточную статистику со значениями в $ \mathbb{R}$ для параметра $ \sigma^2$.

\textit{Решение.}
$$L \left( \vec{X}, \sigma^2 \right) =
  \prod \limits_{i = 1}^n \frac{1}{ \sqrt{2 \pi } \sigma } \cdot e^{- \frac{X_i^2}{2 \sigma^2}} =
  \left( \frac{1}{ \sqrt{2 \pi } \sigma } \right)^n \cdot
  e^{- \frac{ \sum \limits_{i = 1}^n X_i^2}{2 \sigma^2}} =
  \frac{1}{ \left( \sqrt{2 \pi } \sigma \right)^n} \cdot
  e^{- \frac{n \overline{X^2}}{2 \sigma^2}}.$$

Достаточной статистикой будет второй выборочный момент.

$h \left( X_1, \dotsc, X_n \right) = 1$, тогда
$$g \left( \sigma^2, \overline{X^2} \right) =
  \frac{1}{ \left( \sqrt{2 \pi } \sigma \right)^n} \cdot
  e^{- \frac{n \overline{X^2}}{2 \sigma^2}}.$$

Для $ \sigma^2$ достаточная статистика --- $ \hat{ \sigma^2} = \overline{X^2}$.

\subsubsection{5.7}

\textit{Задание.}
Пусть $X_1, \dotsc, X_n$ ---
выборка из равномерного распределения на отрезке $ \left[ 0, \theta \right] $.
Найдите достаточную статистику со значениями в $ \mathbb{R}$ для параметра $ \theta $.

\textit{Решение.}
$$L \left( \vec{X}, \theta \right) =
  \prod \limits_{i = 1}^n
    \frac{1}{ \theta } \cdot \mathbbm{1} \left\{ X_i \in \left[ 0, \theta \right] \right\}.$$
Все $X_i$ должны быть не меньше нуля и не больше $ \theta $.
Получаем
$$ \prod \limits_{i = 1}^n
    \frac{1}{ \theta } \cdot \mathbbm{1} \left\{ X_i \in \left[ 0, \theta \right] \right\} =
  \frac{1}{ \theta^n} \cdot
  \mathbbm{1} \left\{ X_{ \left( 1 \right) } \geq 0, X_{ \left( n \right) } \leq \theta \right\}.$$
Разделим индекатор на 2
$$ \frac{1}{ \theta^n} \cdot
  \mathbbm{1} \left\{ X_{ \left( 1 \right) } \geq 0, X_{ \left( n \right) } \leq \theta \right\} =
  \mathbbm{1} \left\{ X_{ \left( 1 \right) } \geq 0 \right\} \cdot
  \frac{1}{ \theta^n} \cdot \mathbbm{1} \left\{ X_{ \left( n \right) } \leq \theta \right\},$$
где первый индикатор --- это функция $h \left( \vec{X} \right) $, всё остальное ---
$g \left( \theta, X_{ \left( n \right) } \right) $.

Вывод: $X_{ \left( n \right) }$ --- достаточная статистика для $ \theta $.

\subsubsection{5.8}

\textit{Задание.}
Пусть $X_1, \dotsc, X_n$ ---
выборка из равномерного распределения на отрезке $ \left[ a, b \right] $.
Выясните,
какие из статистик
$ \overline{X}, \,
  X_{ \left( n \right) }, \,
  \left( X_{ \left( 1 \right) }, X_{ \left( n \right) }) \right) $
являются достаточными для двумерного параметра $ \left( a, b \right) $.

\textit{Решение.} Для оценки $ \left( a, b \right) $ будет достаточно
$ \left( X_{ \left( 1 \right) }, X_{ \left( n \right) }) \right) $.

Информацию про средину отрезка даёт $ \overline{X}$.
Этой информации недостаточно для оценки концов .

Зная $X_{ \left( n \right) }$, будем знать, где правая граница, следовательно,
этой информации недостаточно.

Ищем функцию правдоподобия
$$L \left( \vec{X}, a, b \right) =
  \prod \limits_{i = 1}^n
    \frac{1}{b - a} \cdot \mathbbm{1} \left\{ X_i \in \left[ a, b \right] \right\} =
  \frac{1}{ \left( b - a \right)^n} \cdot
  \mathbbm{1} \left\{ X_{ \left( 1 \right) } \geq a, X_{ \left( n \right) } \leq b \right\}.$$
Записываем через функции, которые используются в теореме о характеризации достаточной статистики
$$ \frac{1}{ \left( b - a \right)^n} \cdot
  \mathbbm{1} \left\{ X_{ \left( 1 \right) } \geq a, X_{ \left( n \right) } \leq b \right\} =
  g \left( a, b, X_{ \left( 1 \right) }, X_{ \left( n \right) } \right), \,
  h \left( \vec{X} \right) = 1.$$
По теореме о характеризации, $ \left( X_{ \left( 1 \right) }, X_{ \left( n \right) } \right) $ ---
достаточная статистика для $ \left( a, b \right) $.

Допустим, $ \overline{X}$ --- достаточная статистика,
значит должно выполняться
$L \left( \vec{X}, a, b \right) =
  h \left( \vec{X} \right) \cdot g \left( a, b, \overline{X} \right) $.

Пусть имеем две выборки: $X_1^1, \dotsc, X_n^1$ и $X_1^2, \dotsc, X_n^2$,
причём
$$ \overline{X^1} =
  \overline{X^2} =
  c.$$

Допустим, что $X_{ \left( 1 \right) }^1 = a, \, X_{ \left( n \right) }^1 = b$, следовательно,
$X_i^1 \sim U \left( \left[ a, b \right] \right) $.

Вторую выборку подбираем так,
чтобы наблюдаемое значение выходило за пределы $ \left[ a, b \right] $, например,
$X_{ \left( 1 \right) }^2 < a$,
но $X_{ \left( i \right) }^2 \in \left( a, b \right) $ при $i \neq 1$.

Ищем функции правдоподобия для этих двух выборок
$$L \left( \vec{X^1} \right) =
  \frac{1}{ \left( b - a \right)^n} =
  h \left( \vec{X^1} \right) \cdot g \left( a, b, c \right), \,
  L \left( \vec{X^2} \right) =
  0 =
  h \left( \vec{X^2} \right) g \left( a, b, c \right).$$

Ноль --- реакция на индикатор.

Если бы взяли выборку внутри $ \left( a, b \right) $, то ничего бы не поменялось.

Но как только пересекаем границу, то есть реакция, то есть $h$ уже зависит от концов отрезка,
$h$ зависит от $a, b$.

Для статистики $X_{ \left( n \right) }$ --- аналогично.

\subsubsection{5.9}

\textit{Задание.}
Пусть $X_1, \dotsc, X_n$ ---
выборка из равномерного распределения на отрезке
$ \left[ a \left( \theta\ \right), b \left( \theta \right) \right] $.
Докажите,
что если $a \left( \theta \right) \uparrow, \, b \left( \theta \right) \downarrow $ с возрастанием
$ \theta $,
то статистика
$T =
  \min \left(
    a^{-1} \left( X_{ \left( 1 \right) } \right), b^{-1} \left( X_{ \left( n \right) } \right)
  \right) $
достаточная для параметра $ \theta $.

\textit{Решение.} Записываем функцию правдоподобия
$$L \left( \vec{X}, a \left( \theta \right), b \left( \theta \right) \right) =
  \prod \limits_{i = 1}^n
    \frac{1}{b \left( \theta \right) - a \left( \theta \right) } \cdot
    \mathbbm{1} \left\{
      X_i \in \left[ a \left( \theta \right), b \left( \theta \right) \right]
    \right\}.$$
Вычисляем произведение
\begin{equation*}
  \begin{split}
    \prod \limits_{i = 1}^n
      \frac{1}{b \left( \theta \right) - a \left( \theta \right) } \cdot
      \mathbbm{1} \left\{
        X_i \in \left[ a \left( \theta \right), b \left( \theta \right) \right]
      \right\} = \\
    = \frac{1}{ \left[ b \left( \theta \right) - a \left( \theta \right) \right]^n} \cdot
    \mathbbm{1} \left\{
      X_{ \left( 1 \right) } \geq a \left( \theta \right), \,
      X_{ \left( n \right) } \leq b \left( \theta \right)
    \right\}.
  \end{split}
\end{equation*}
Это строго монотонные функции.
Можем решить неравенства относительно $ \theta $.
Получим
\begin{equation*}
  \begin{split}
    \frac{1}{ \left[ b \left( \theta \right) - a \left( \theta \right) \right]^n} \cdot
    \mathbbm{1} \left\{
      X_{ \left( 1 \right) } \geq a \left( \theta \right), \,
      X_{ \left( n \right) } \leq b \left( \theta \right)
    \right\} = \\
    = \frac{1}{ \left[ b \left( \theta \right) - a \left( \theta \right) \right]^n} \cdot
    \mathbbm{1} \left\{
      \theta \leq a^{-1} \left( X_{ \left( 1 \right) } \right), \,
      \theta \leq b^{-1} \left( X_{ \left( n \right) } \right)
    \right\} = \\
    = \frac{1}{ \left[ b \left( \theta \right) - a \left( \theta \right) \right]^n} \cdot
    \mathbbm{1} \left\{ \theta \leq T \right\} =
    g \left( \theta, T \right),
  \end{split}
\end{equation*}
а $h \equiv 1$.

Отсюда $T$ --- достаточная статистика для $ \theta $.

\addcontentsline{toc}{section}{Домашнее задание}
\section*{Домашнее задание}
